{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "data = pd.read_csv('M1_final.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we can find some correlation between data features\n",
    "corr_jfk = data.corr(numeric_only=True)\n",
    "fig,ax = plt.subplots(figsize=(20,10), )\n",
    "sns.heatmap(corr_jfk, cmap=\"coolwarm\", linewidths=0.5, ax=ax, annot= True)\n",
    "plt.title('Correlation of JKF data Feature ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select numerical columns for histogram plotting\n",
    "numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Set up the plot size and layout\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot histograms for the first 6 numerical features\n",
    "for i, col in enumerate(numerical_columns[:16], 1):\n",
    "    plt.subplot(4,4,i)\n",
    "    plt.hist(data[col].dropna(), bins=30, color='skyblue', edgecolor='black', )\n",
    "    plt.title(f'Histogram of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define features and the target\n",
    "features = ['DEP_DELAY', 'DISTANCE', 'CRS_DEP_M', 'Wind Speed', 'Humidity', 'sch_dep', 'sch_arr']\n",
    "target = 'TAXI_OUT'\n",
    "\n",
    "# Prepare dictionary to store values for each feature and model\n",
    "mse_results = {feature: {} for feature in features}\n",
    "r2_results = {feature: {} for feature in features} \n",
    "mapr_results = {feature: {} for feature in features}\n",
    "\n",
    "# Define models to use\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Gradient Descent': SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    'Lasso': Lasso(alpha=0.1),\n",
    "    'Ridge': Ridge(alpha=0.1),\n",
    "}\n",
    "\n",
    "# Iterate over each feature and train each model\n",
    "for feature in features:\n",
    "    X = data[[feature]]\n",
    "    y = data[target]\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test,y_pred)\n",
    "        absolute_per_error = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "        # Store MSE result\n",
    "        mse_results[feature][model_name] = mse\n",
    "        r2_results[feature][model_name] = r2\n",
    "        mapr_results[feature][model_name] = absolute_per_error\n",
    "\n",
    "# Convert MSE results to a DataFrame for visualization\n",
    "mse_df = pd.DataFrame(mse_results).T\n",
    "r2_score_df = pd.DataFrame(r2_results).T * 100\n",
    "mapr_df = pd.DataFrame(mapr_results).T\n",
    "# Plot MSE for each feature and model\n",
    "mse_df.plot(kind='line', figsize=(10, 6))\n",
    "plt.title(\"Model Evaluation (MSE) for Each Feature\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot r2 for each feature and model\n",
    "r2_score_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Model Evaluation (r2_score) for Each Feature\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"r2 score\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mapr_df.plot(kind='line', figsize=(10, 6))\n",
    "plt.title(\"Model Evaluation (Mean_absolute_perc_error ) for Each Feature\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"map_error\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
